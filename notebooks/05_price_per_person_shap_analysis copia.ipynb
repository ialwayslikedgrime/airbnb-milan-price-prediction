{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **05 INTERPRETABILITY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from category_encoders import *\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_validate,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    "    cross_val_score\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    FunctionTransformer,\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    HistGradientBoostingRegressor,\n",
    "    ExtraTreesRegressor\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# ——— Additional models ————————————————————————\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file at: /Users/stellaandorno/Desktop/github_public/airbnb_milan/notebooks/data/interim/data_preprocessed.parquet\n",
      "Alternate path: /Users/stellaandorno/Desktop/github_public/airbnb_milan/data/interim/data_preprocessed.parquet\n",
      "Successfully loaded the dataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Project root & data paths\n",
    "project_root = Path().resolve()\n",
    "df_pre_path = project_root / \"data\" / \"interim\" / \"data_preprocessed.parquet\"\n",
    "\n",
    "# Print the path to verify it exists\n",
    "print(f\"Looking for file at: {df_pre_path}\")\n",
    "\n",
    "# Check if file exists before reading\n",
    "if not df_pre_path.exists():\n",
    "\t# Try alternate path\n",
    "\tdf_pre_path = project_root.parent / \"data\" / \"interim\" / \"data_preprocessed.parquet\"\n",
    "\tprint(f\"Alternate path: {df_pre_path}\")\n",
    "\n",
    "if df_pre_path.exists():\n",
    "\tdf = pd.read_parquet(df_pre_path)\n",
    "\tprint(\"Successfully loaded the dataset\")\n",
    "else:\n",
    "\traise FileNotFoundError(f\"Could not find the parquet file at {df_pre_path}\")\n",
    "\n",
    "src_path = project_root / \"src\"\n",
    "if src_path.exists():\n",
    "\tsys.path.append(str(src_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing, I remove outliers in the target variable price, and I log-transform it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split FIRST on raw data to avoid data leakage\n",
    "X = df.drop(columns=[\"price\"])\n",
    "\n",
    "# Create price_per_person target\n",
    "df[\"price_per_person\"] = df[\"price\"] / df[\"accommodates\"]\n",
    "y = df[\"price_per_person\"]\n",
    "\n",
    "# Train-test split BEFORE outlier removal\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Remove outliers only from training set\n",
    "Q1 = y_train.quantile(0.25)  # Only training data\n",
    "Q3 = y_train.quantile(0.75)  # Only training data\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Apply to training set only\n",
    "train_mask = (y_train >= lower_bound) & (y_train <= upper_bound)\n",
    "X_train = X_train[train_mask]\n",
    "y_train = y_train[train_mask]\n",
    "\n",
    "# Log-transform after outlier removal\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)  # Transform test, but don't remove outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now recall the features in their respective categories in order to be able to feed them to the pipeline, recalling what I did in the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 4. Define feature groups\n",
    "numeric_features = [\n",
    "    'host_listings_count', 'host_total_listings_count', 'bathrooms', 'bedrooms', 'beds',\n",
    "    'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm',\n",
    "    'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
    "    'calculated_host_listings_count',\n",
    "    'calculated_host_listings_count_private_rooms',\n",
    "    'reviews_per_month', 'days_since_host_since',\n",
    "    'air_conditioning', 'elevator', 'fast_wifi', 'parking',\n",
    "    'coffee_machine', 'washer', 'self_check_in', 'streaming_tv',\n",
    "    'dedicated_workspace', 'private_entrance', 'kitchen_appliances',\n",
    "    'heating', 'hot_water', 'safety_equipment', 'clothing_storage',\n",
    "    'balcony', 'premium_views', 'dishwasher', 'gym'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'neighbourhood_cleansed',\n",
    "    'property_type',\n",
    "    'room_type',\n",
    "    'host_location'\n",
    "]\n",
    "\n",
    "ordinal_features_days = [\n",
    "    'days_since_first_review',\n",
    "    'days_since_last_review'\n",
    "]\n",
    "\n",
    "# I will keep just one since they are very correlated\n",
    "ordinal_features_reviews = [\n",
    "    'review_scores_rating',\n",
    "    'review_scores_accuracy',\n",
    "    'review_scores_cleanliness',\n",
    "    'review_scores_checkin',\n",
    "    'review_scores_communication',\n",
    "    'review_scores_location',\n",
    "    'review_scores_value']\n",
    "\n",
    "ordinal_features = ordinal_features_days + ordinal_features_reviews\n",
    "\n",
    "# 5. Define category orders for OrdinalEncoder\n",
    "first_review_order = [\n",
    "    'no_review_yet',\n",
    "    'very_new (<= 1 month)',\n",
    "    'new (<= 6 months)',\n",
    "    'established (<= 1 year)',\n",
    "    'mature (<= 3 years)',\n",
    "    'veteran (<= 5 years)',\n",
    "    'legacy (over 5 years)'\n",
    "]\n",
    "\n",
    "last_review_order = [\n",
    "    'no_review',\n",
    "    'very_recent (<= 1 week)',\n",
    "    'recent (<= 1 month)',\n",
    "    'somewhat_recent (<= 3 months)',\n",
    "    'old (<= 6 months)',\n",
    "    'very_old (<= 1 year)',\n",
    "    'dormant (over a year)'\n",
    "]\n",
    "\n",
    "\n",
    "review_order = [\"no_reviews\", \"low_reviews\", \"medium_reviews\", \"high_reviews\", \"top_reviews\"]\n",
    "\n",
    "all_ord_categories = (\n",
    "    [first_review_order, last_review_order] +\n",
    "    [review_order] * len(ordinal_features_reviews)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Build transformers\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline([\n",
    "    (\"ordinal\", OrdinalEncoder(categories=all_ord_categories))\n",
    "])\n",
    "\n",
    "# 7. Combine into ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer,   numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features),\n",
    "    (\"ord\", ordinal_transformer,    ordinal_features),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# 8. Create full Pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"select\", SelectKBest(k=50)),\n",
    "    (\"regressor\", RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_params = {\n",
    "\n",
    "\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor(objective=\"reg:squarederror\", n_jobs=-1, random_state=42),\n",
    "        'params': {\n",
    "            'regressor__n_estimators': randint(200, 1000),\n",
    "            'regressor__max_depth': randint(4, 12),\n",
    "            'regressor__learning_rate': loguniform(0.01, 0.3),\n",
    "            'regressor__subsample': uniform(0.6, 0.4),\n",
    "            'regressor__colsample_bytree': uniform(0.6, 0.4),\n",
    "            'regressor__gamma': loguniform(1e-8, 1e-1),\n",
    "            'select__k': randint(30, 120)\n",
    "        }\n",
    "    },\n",
    "    \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cross_validation_regression(X, y, models_and_params, outer_cv=5, inner_cv=3, \n",
    "                                     n_iter=20, scoring='r2', random_state=42):\n",
    "    \"\"\"\n",
    "    Perform nested cross-validation for regression model selection and performance estimation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Feature matrix\n",
    "    y : array-like, shape (n_samples,)\n",
    "        Target vector\n",
    "    models_and_params : dict\n",
    "        Dictionary containing models and their hyperparameter grids\n",
    "    outer_cv : int\n",
    "        Number of folds for outer cross-validation\n",
    "    inner_cv : int\n",
    "        Number of folds for inner cross-validation (hyperparameter tuning)\n",
    "    n_iter : int\n",
    "        Number of parameter settings sampled for RandomizedSearchCV\n",
    "    scoring : str\n",
    "        Scoring metric\n",
    "    random_state : int\n",
    "        Random state for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary containing results for each model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize cross-validation splitters\n",
    "    outer_cv_splitter = KFold(n_splits=outer_cv, shuffle=True, random_state=random_state)\n",
    "    inner_cv_splitter = KFold(n_splits=inner_cv, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"=== NESTED CROSS-VALIDATION FOR AIRBNB PRICE PREDICTION ===\\n\")\n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    print(f\"Target range: {y.min():.3f} - {y.max():.3f} (log-transformed)\")\n",
    "    print(f\"Outer CV: {outer_cv} folds, Inner CV: {inner_cv} folds\")\n",
    "    print(f\"Hyperparameter search iterations: {n_iter}\\n\")\n",
    "    \n",
    "    for model_name, model_config in models_and_params.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        # Create pipeline with preprocessing, feature selection, and classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('select', SelectKBest(k=50)),  # Default value, will be tuned if in params\n",
    "            ('regressor', model_config['model'])\n",
    "        ])\n",
    "        \n",
    "        # Outer loop: Performance estimation\n",
    "        outer_scores = []\n",
    "        best_params_per_fold = []\n",
    "        \n",
    "        fold = 1\n",
    "        for train_idx, test_idx in outer_cv_splitter.split(X):\n",
    "            print(f\"  Processing outer fold {fold}/{outer_cv}\")\n",
    "            \n",
    "            X_train_outer, X_test_outer = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train_outer, y_test_outer = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            # Inner loop: Hyperparameter optimization\n",
    "            if model_config['params']:  # Only tune if there are parameters to tune\n",
    "                search = RandomizedSearchCV(\n",
    "                    pipeline, \n",
    "                    model_config['params'],\n",
    "                    cv=inner_cv_splitter,\n",
    "                    scoring=scoring,\n",
    "                    n_iter=n_iter,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=random_state,\n",
    "                    return_train_score=False\n",
    "                )\n",
    "                \n",
    "                # Fit grid search on outer training set\n",
    "                search.fit(X_train_outer, y_train_outer)\n",
    "                \n",
    "                # Get best model from inner CV\n",
    "                best_model = search.best_estimator_\n",
    "                best_params_per_fold.append(search.best_params_)\n",
    "            else:\n",
    "                # No hyperparameters to tune, just fit the pipeline\n",
    "                pipeline.fit(X_train_outer, y_train_outer)\n",
    "                best_model = pipeline\n",
    "                best_params_per_fold.append({})\n",
    "            \n",
    "            # Evaluate best model on outer test set\n",
    "            y_pred = best_model.predict(X_test_outer)\n",
    "            if scoring == 'r2':\n",
    "                fold_score = r2_score(y_test_outer, y_pred)\n",
    "            elif scoring == 'neg_mean_squared_error':\n",
    "                fold_score = -mean_squared_error(y_test_outer, y_pred)\n",
    "            elif scoring == 'neg_mean_absolute_error':\n",
    "                fold_score = -mean_absolute_error(y_test_outer, y_pred)\n",
    "            else:\n",
    "                fold_score = best_model.score(X_test_outer, y_test_outer)\n",
    "            \n",
    "            outer_scores.append(fold_score)\n",
    "            fold += 1\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name] = {\n",
    "            'outer_scores': outer_scores,\n",
    "            'mean_score': np.mean(outer_scores),\n",
    "            'std_score': np.std(outer_scores),\n",
    "            'best_params_per_fold': best_params_per_fold\n",
    "        }\n",
    "        \n",
    "        print(f\"  Mean {scoring}: {np.mean(outer_scores):.4f} (+/- {np.std(outer_scores):.4f})\")\n",
    "        print(f\"  Individual fold scores: {[f'{score:.4f}' for score in outer_scores]}\")\n",
    "        print()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def select_best_model_and_retrain(X, y, models_and_params, results, inner_cv=3, n_iter=50):\n",
    "    \"\"\"\n",
    "    Select the best model based on nested CV results and retrain on full dataset.\n",
    "    \"\"\"\n",
    "    # Find best model\n",
    "    best_model_name = max(results.keys(), key=lambda k: results[k]['mean_score'])\n",
    "    best_model_config = models_and_params[best_model_name]\n",
    "    \n",
    "    print(f\"=== BEST MODEL SELECTION ===\")\n",
    "    print(f\"Best model: {best_model_name}\")\n",
    "    print(f\"Expected performance: {results[best_model_name]['mean_score']:.4f} \"\n",
    "          f\"(+/- {results[best_model_name]['std_score']:.4f})\")\n",
    "    print()\n",
    "    \n",
    "    # Retrain best model on full dataset with hyperparameter tuning\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('select', SelectKBest(k=50)),\n",
    "        ('regressor', best_model_config['model'])\n",
    "    ])\n",
    "    \n",
    "    if best_model_config['params']:\n",
    "        inner_cv_splitter = KFold(n_splits=inner_cv, shuffle=True, random_state=42)\n",
    "        \n",
    "        final_search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            best_model_config['params'],\n",
    "            cv=inner_cv_splitter,\n",
    "            scoring='r2',\n",
    "            n_iter=n_iter,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        final_search.fit(X, y)\n",
    "        final_model = final_search.best_estimator_\n",
    "        \n",
    "        print(f\"Final model hyperparameters: {final_search.best_params_}\")\n",
    "        print(f\"Cross-validation score on full dataset: {final_search.best_score_:.4f}\")\n",
    "    else:\n",
    "        pipeline.fit(X, y)\n",
    "        final_model = pipeline\n",
    "        print(\"No hyperparameters to tune for this model.\")\n",
    "    \n",
    "    return final_model, best_model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Nested Cross-Validation for Airbnb Price Prediction...\n",
      "Training set shape: (16348, 55)\n",
      "Test set shape: (4393, 55)\n",
      "\n",
      "=== NESTED CROSS-VALIDATION FOR AIRBNB PRICE PREDICTION ===\n",
      "\n",
      "Dataset shape: (16348, 55)\n",
      "Target range: 3.750 - 125.333 (log-transformed)\n",
      "Outer CV: 5 folds, Inner CV: 3 folds\n",
      "Hyperparameter search iterations: 20\n",
      "\n",
      "Evaluating XGBoost...\n",
      "  Processing outer fold 1/5\n",
      "  Processing outer fold 2/5\n",
      "  Processing outer fold 3/5\n",
      "  Processing outer fold 4/5\n",
      "  Processing outer fold 5/5\n",
      "  Mean r2: 0.3852 (+/- 0.0104)\n",
      "  Individual fold scores: ['0.3930', '0.3906', '0.3935', '0.3830', '0.3658']\n",
      "\n",
      "=== BEST MODEL SELECTION ===\n",
      "Best model: XGBoost\n",
      "Expected performance: 0.3852 (+/- 0.0104)\n",
      "\n",
      "Final model hyperparameters: {'regressor__colsample_bytree': np.float64(0.8663689426469987), 'regressor__gamma': np.float64(0.00013774775007214802), 'regressor__learning_rate': np.float64(0.02545642421255076), 'regressor__max_depth': 6, 'regressor__n_estimators': 938, 'regressor__subsample': np.float64(0.6478376983753207), 'select__k': 107}\n",
      "Cross-validation score on full dataset: 0.3830\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Starting Nested Cross-Validation for Airbnb Price Prediction...\")\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print()\n",
    "\n",
    "# Perform nested cross-validation (reduced subset for demonstration)\n",
    "# You can include all models by using the full models_and_params dictionary\n",
    "selected_models = models_and_params\n",
    "\n",
    "\n",
    "cv_results = nested_cross_validation_regression(\n",
    "    X_train, y_train, \n",
    "    selected_models,  # Use selected_models or models_and_params for all\n",
    "    outer_cv=5, \n",
    "    inner_cv=3, \n",
    "    n_iter=20,  # Reduced for faster execution\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "# Select and retrain best model\n",
    "final_model, best_model_name = select_best_model_and_retrain(\n",
    "    X_train, y_train, selected_models, cv_results, n_iter=30\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL EVALUATION ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL TEST SET EVALUATION ===\n",
      "Test R² (on log-transformed data): -5881.0476\n",
      "Test RMSE (on log-transformed data): 48.5900\n",
      "Test MAE (on log-transformed data): 45.9382\n",
      "\n",
      "In original price scale:\n",
      "Test RMSE: $21957.00\n",
      "Test MAE: $21954.24\n",
      "\n",
      "Prediction Statistics:\n",
      "Mean predicted price: $22020.76\n",
      "Median predicted price: $22025.46\n",
      "Min predicted price: $1359.56\n",
      "Max predicted price: $22025.46\n",
      "\n",
      "=== NESTED CV SUMMARY ===\n",
      "     Model  Mean_R2  Std_R2  CI_Lower  CI_Upper\n",
      "0  XGBoost   0.3852  0.0104    0.3648    0.4056\n",
      "\n",
      "Selected model: XGBoost\n",
      "Note: The nested CV performance estimates represent unbiased estimates\n",
      "of how well each model is expected to perform on unseen data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n=== FINAL TEST SET EVALUATION ===\")\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics on log-transformed data\n",
    "test_r2 = r2_score(y_test_log, y_pred_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_log, y_pred_test))\n",
    "test_mae = mean_absolute_error(y_test_log, y_pred_test)\n",
    "\n",
    "print(f\"Test R² (on log-transformed data): {test_r2:.4f}\")\n",
    "print(f\"Test RMSE (on log-transformed data): {test_rmse:.4f}\")\n",
    "print(f\"Test MAE (on log-transformed data): {test_mae:.4f}\")\n",
    "\n",
    "# Safely convert predictions back to original scale\n",
    "try:\n",
    "    # Clip predictions to avoid extreme values\n",
    "    y_pred_clipped = np.clip(y_pred_test, 0, 10)  # Limit maximum log value\n",
    "    y_pred_original = np.expm1(y_pred_clipped)\n",
    "    y_test_actual = y_test  # Original non-logged values\n",
    "    \n",
    "    # Calculate metrics on original scale\n",
    "    test_rmse_original = np.sqrt(mean_squared_error(y_test_actual, y_pred_original))\n",
    "    test_mae_original = mean_absolute_error(y_test_actual, y_pred_original)\n",
    "    \n",
    "    print(f\"\\nIn original price scale:\")\n",
    "    print(f\"Test RMSE: ${test_rmse_original:.2f}\")\n",
    "    print(f\"Test MAE: ${test_mae_original:.2f}\")\n",
    "    \n",
    "    # Additional statistics\n",
    "    print(\"\\nPrediction Statistics:\")\n",
    "    print(f\"Mean predicted price: ${np.mean(y_pred_original):.2f}\")\n",
    "    print(f\"Median predicted price: ${np.median(y_pred_original):.2f}\")\n",
    "    print(f\"Min predicted price: ${np.min(y_pred_original):.2f}\")\n",
    "    print(f\"Max predicted price: ${np.max(y_pred_original):.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nWarning: Could not calculate metrics in original scale: {str(e)}\")\n",
    "\n",
    "# Summary of all models\n",
    "print(\"\\n=== NESTED CV SUMMARY ===\")\n",
    "cv_summary = pd.DataFrame([\n",
    "    {\n",
    "        'Model': model_name,\n",
    "        'Mean_R2': result['mean_score'],\n",
    "        'Std_R2': result['std_score'],\n",
    "        'CI_Lower': result['mean_score'] - 1.96 * result['std_score'],\n",
    "        'CI_Upper': result['mean_score'] + 1.96 * result['std_score']\n",
    "    }\n",
    "    for model_name, result in cv_results.items()\n",
    "]).sort_values('Mean_R2', ascending=False)\n",
    "\n",
    "print(cv_summary.round(4))\n",
    "\n",
    "print(f\"\\nSelected model: {best_model_name}\")\n",
    "print(\"Note: The nested CV performance estimates represent unbiased estimates\")\n",
    "print(\"of how well each model is expected to perform on unseen data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_feature_names(pipeline, X_sample):\n",
    "    \"\"\"Extract real feature names after preprocessing\"\"\"\n",
    "    preprocessor = pipeline.named_steps['preprocessor']\n",
    "    feature_names = []\n",
    "    \n",
    "    # Process each transformer\n",
    "    for name, transformer, columns in preprocessor.transformers_:\n",
    "        if name == 'num':\n",
    "            feature_names.extend(columns)\n",
    "        elif name == 'cat':\n",
    "            ohe = transformer.named_steps['ohe']\n",
    "            sample_data = X_sample[columns]\n",
    "            ohe.fit(sample_data)\n",
    "            cat_feature_names = ohe.get_feature_names_out(columns)\n",
    "            feature_names.extend(cat_feature_names)\n",
    "        elif name == 'ord':\n",
    "            feature_names.extend(columns)\n",
    "    \n",
    "    # Apply feature selection\n",
    "    selector = pipeline.named_steps['select']\n",
    "    X_transformed = preprocessor.transform(X_sample)\n",
    "    selector.fit(X_transformed, y_train.iloc[:len(X_sample)])\n",
    "    selected_mask = selector.get_support()\n",
    "    selected_features = [name for name, selected in zip(feature_names, selected_mask) if selected]\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Extract real feature names\n",
    "sample_size = min(1000, len(X_train))\n",
    "X_sample = X_train.iloc[:sample_size]\n",
    "real_feature_names = get_real_feature_names(final_model, X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 1. XGBOOST BUILT-IN FEATURE IMPORTANCE\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBOOST FEATURE IMPORTANCE ANALYSIS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# FEATURE IMPORTANCE AND SHAP ANALYSIS\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "# 1. XGBOOST BUILT-IN FEATURE IMPORTANCE\n",
    "print(\"XGBOOST FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Extract the XGBoost regressor from the pipeline\n",
    "xgb_regressor = final_model.named_steps['regressor']\n",
    "importance = xgb_regressor.feature_importances_\n",
    "\n",
    "# Create feature importance DataFrame with real names\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': real_feature_names[:len(importance)],\n",
    "    'importance': importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "print(importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_15 = importance_df.head(15)\n",
    "plt.barh(range(len(top_15)), top_15['importance'])\n",
    "plt.yticks(range(len(top_15)), top_15['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('XGBoost Feature Importance - Top 15 Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =====================================================\n",
    "# 2. SHAP ANALYSIS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\nSHAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prepare data for SHAP\n",
    "X_test_transformed = final_model[:-1].transform(X_test)\n",
    "\n",
    "# Sample for computational efficiency\n",
    "sample_size = 500\n",
    "if len(X_test_transformed) > sample_size:\n",
    "    np.random.seed(42)\n",
    "    sample_indices = np.random.choice(len(X_test_transformed), sample_size, replace=False)\n",
    "    X_sample = X_test_transformed[sample_indices]\n",
    "else:\n",
    "    X_sample = X_test_transformed\n",
    "    sample_indices = np.arange(len(X_test_transformed))\n",
    "\n",
    "print(f\"Analyzing {len(X_sample)} predictions with SHAP TreeExplainer...\")\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(xgb_regressor)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "print(f\"SHAP values computed: {shap_values.shape}\")\n",
    "\n",
    "# SHAP Feature Importance Bar Plot\n",
    "print(\"\\nSHAP Feature Importance Ranking:\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_sample, \n",
    "                  feature_names=real_feature_names[:shap_values.shape[1]],\n",
    "                  plot_type=\"bar\", max_display=15, show=False)\n",
    "plt.title(\"SHAP Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# SHAP Summary Plot\n",
    "print(\"\\nSHAP Impact Direction Analysis:\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_sample,\n",
    "                  feature_names=real_feature_names[:shap_values.shape[1]],\n",
    "                  max_display=15, show=False)\n",
    "plt.title(\"SHAP Summary: Feature Values vs Impact on Price\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Individual Prediction Explanation\n",
    "print(\"\\nIndividual Prediction Explanation:\")\n",
    "try:\n",
    "    shap.waterfall_plot(explainer.expected_value, shap_values[0], X_sample[0],\n",
    "                       feature_names=real_feature_names[:shap_values.shape[1]],\n",
    "                       max_display=10)\n",
    "    \n",
    "    # Prediction details\n",
    "    actual_price = np.expm1(y_test.iloc[sample_indices[0]])\n",
    "    predicted_price = np.expm1(final_model.predict(X_test.iloc[sample_indices[0]:sample_indices[0]+1])[0])\n",
    "    \n",
    "    print(f\"Actual Price: ${actual_price:.2f}\")\n",
    "    print(f\"Predicted Price: ${predicted_price:.2f}\")\n",
    "    print(f\"Absolute Error: ${abs(actual_price - predicted_price):.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Waterfall plot error: {e}\")\n",
    "\n",
    "# SHAP Feature Ranking\n",
    "mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "shap_ranking = pd.DataFrame({\n",
    "    'feature': real_feature_names[:len(mean_abs_shap)],\n",
    "    'mean_abs_shap': mean_abs_shap\n",
    "}).sort_values('mean_abs_shap', ascending=False)\n",
    "\n",
    "print(\"\\nSHAP Feature Ranking (Top 15):\")\n",
    "print(shap_ranking.head(15).to_string(index=False))\n",
    "\n",
    "# =====================================================\n",
    "# 3. METHODOLOGY COMPARISON\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\nMETHODOLOGY COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Merge importance measures\n",
    "comparison = pd.merge(\n",
    "    importance_df.head(15)[['feature', 'importance']].rename(columns={'importance': 'XGBoost_Importance'}),\n",
    "    shap_ranking.head(15)[['feature', 'mean_abs_shap']].rename(columns={'mean_abs_shap': 'SHAP_Importance'}),\n",
    "    on='feature',\n",
    "    how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "# Calculate rank correlation\n",
    "xgb_ranks = comparison['XGBoost_Importance'].rank(ascending=False)\n",
    "shap_ranks = comparison['SHAP_Importance'].rank(ascending=False)\n",
    "correlation = xgb_ranks.corr(shap_ranks)\n",
    "\n",
    "print(f\"Rank correlation between XGBoost and SHAP importance: {correlation:.3f}\")\n",
    "\n",
    "if correlation > 0.7:\n",
    "    print(\"Assessment: Strong agreement between methods\")\n",
    "elif correlation > 0.5:\n",
    "    print(\"Assessment: Moderate agreement between methods\")\n",
    "else:\n",
    "    print(\"Assessment: Low agreement - requires further investigation\")\n",
    "\n",
    "# =====================================================\n",
    "# 4. BUSINESS ANALYSIS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\nBUSINESS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Categorize top features\n",
    "top_5_features = importance_df.head(5)\n",
    "\n",
    "print(\"Top 5 Pricing Drivers:\")\n",
    "for i, (_, row) in enumerate(top_5_features.iterrows(), 1):\n",
    "    feature_name = row['feature']\n",
    "    importance_val = row['importance']\n",
    "    \n",
    "    # Determine category\n",
    "    if 'property_type' in feature_name.lower():\n",
    "        category = \"Property Type\"\n",
    "    elif 'neighbourhood' in feature_name.lower():\n",
    "        category = \"Location\"\n",
    "    elif any(word in feature_name.lower() for word in ['accommodates', 'bedrooms', 'bathrooms', 'beds']):\n",
    "        category = \"Size/Capacity\"\n",
    "    elif 'review' in feature_name.lower() or 'rating' in feature_name.lower():\n",
    "        category = \"Reviews\"\n",
    "    elif 'room_type' in feature_name.lower():\n",
    "        category = \"Room Type\"\n",
    "    else:\n",
    "        category = \"Amenities/Other\"\n",
    "    \n",
    "    print(f\"{i}. {category}: {feature_name} (Importance: {importance_val:.4f})\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"1. Property type is the primary pricing differentiator\")\n",
    "print(\"2. Location creates significant value premiums\")  \n",
    "print(\"3. Property size directly correlates with pricing power\")\n",
    "print(\"4. Review quality affects competitive positioning\")\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\"1. Optimize property type classification and marketing\")\n",
    "print(\"2. Leverage location advantages in pricing strategy\")\n",
    "print(\"3. Consider capacity optimization where feasible\")\n",
    "print(\"4. Maintain review quality standards\")\n",
    "\n",
    "print(f\"\\nModel Performance Summary:\")\n",
    "test_r2 = r2_score(y_test, final_model.predict(X_test))\n",
    "print(f\"R-squared: {test_r2:.4f}\")\n",
    "print(f\"Explained variance: {test_r2*100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
